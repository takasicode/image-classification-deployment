# -*- coding: utf-8 -*-
"""image-classification-deployment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r8zWKRb1LYk2XXRKfUsYuDCD9R7fPPYr

# Proyek Akhir : Image Classification Model Deployment
Nama Lengkap : Muhammad Fadhil Abyansyah

Username : fadhil-abyansyah

Email : infofadhil29@gmail.com

## Import semua Library yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
import os, zipfile, shutil, PIL.Image
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from tensorflow.keras.utils import plot_model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import RMSprop

"""## Ekstrak Dataset"""

local_zip = 'D:\Image-classification-deployment\cell-images-for-detecting-malaria.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('D:\Image-classification-deployment')
zip_ref.close()

"""## Deklarasi Direktori Dasar"""

BASE_DIR = 'D:\Image-classification-deployment\cell_images'

"""## Mengidentifikasi Jumlah File"""

def list_files(startpath):
    num_files = 0
    for root, dirs, files in os.walk(startpath):
        level = root.replace(startpath, '').count(os.sep)
        indent = ' ' * 2 * (level)
        num_files += len(files)
        print('{}{}/ {}'.format(indent, os.path.basename(root), (str(len(files)) + ' images' if len(files) > 0 else '')))

    return num_files

list_files(BASE_DIR)

"""## Membaca setiap file"""

def read_files(startpath):
    image_files = []
    for dirname, dirnames, filenames in os.walk(startpath):
        for filename in filenames:
            if filename.lower().endswith(('.jpg', '.png')):
                image_files.append(os.path.join(dirname, filename))

    return image_files

"""## Memastikan ukuran image yang beragam dengan fungsi PIL"""

full_dirs = read_files(BASE_DIR + "\cell_images")

image_sizes = []
for file in full_dirs:
    try:
        with PIL.Image.open(file) as image:
            width, height = image.size
            image_sizes.append(f'{width}x{height}')
    except Exception as e:
        print(f"Error processing {file}: {e}")

unique_sizes = set(image_sizes)

print(f'Size all images: {len(image_sizes)}')
print(f'Size unique images: {len(unique_sizes)}')
print(f'First 10 unique images: \n{list(unique_sizes)[:10]}')

"""## Augmentasi Data"""

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    zoom_range=0.2,
    shear_range=0.2,
    rotation_range=0.2
)

"""## Pembuatan Generator untuk Data Pelatihan dan Data Validasi"""

training_generator = datagen.flow_from_directory(
    BASE_DIR + "\cell_images",
    subset='training',
    target_size=(120,120),
    seed=42,
    batch_size=64,
    interpolation='nearest',
    class_mode='binary',
    classes=['Parasitized','Uninfected']
)

validation_generator = datagen.flow_from_directory(
    BASE_DIR + "\cell_images",
    subset='validation',
    target_size=(120,120),
    seed=42,
    batch_size=64,
    interpolation='nearest',
    class_mode='binary',
    classes=['Parasitized','Uninfected']
)

"""## Pembuatan Model"""

model = Sequential([
    Conv2D(64, (3,3), activation='relu', input_shape=(120, 120, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Dropout(0.6),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(256, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Dropout(0.4),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

model.summary()

"""## Callback untuk Menghentikan Pelatihan"""

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if((logs.get('accuracy') > 0.92) and (logs.get('val_accuracy') > 0.92)):
            self.model.stop_training = True
            print("\nAkurasi set pelatihan dan set validasi telah mencapai > 92%!")
callbacks = myCallback()

"""## Kompilasi dan Pelatihan Model"""

LR = 1e-4
model.compile(loss='binary_crossentropy',
    optimizer=RMSprop(learning_rate=LR),
    metrics=['accuracy'])

result = model.fit(
    training_generator,
    validation_data=validation_generator,
    epochs=25,
    steps_per_epoch=100,
    validation_steps=35,
    callbacks=[callbacks],
    verbose=1
)

"""## Membuat plot terhadap akurasi model"""

acc = result.history['accuracy']
val_acc = result.history['val_accuracy']
plt.figure(figsize=(15, 5))

plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.plot(acc, label='Training set')
plt.plot(val_acc, label='Validation set', linestyle='--')
plt.legend()
plt.grid(linestyle='--', linewidth=1, alpha=0.5)

plt.show()

"""## Membuat plot terhadap loss model"""

loss = result.history['loss']
val_loss = result.history['val_loss']
plt.figure(figsize=(15, 5))

plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.plot(loss, label='Training set')
plt.plot(val_loss, label='Validation set', linestyle='--')
plt.legend()
plt.grid(linestyle='--', linewidth=1, alpha=0.5)
plt.show()

"""## Menyimpan model ke dalam format TF-Lite"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model__v1.tflite', 'wb') as f:
    f.write(tflite_model)